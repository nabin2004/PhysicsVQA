{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df56c7b7-4f36-491a-9767-068556e43c52",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0233e654-cfbe-4575-9253-09a76b49e111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoProcessor\n",
    "from transformers.image_utils import load_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafd71d8-bbfa-49f1-bf1e-c0e15013fdb3",
   "metadata": {},
   "source": [
    "### Image Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1606aa3-4771-4abe-ab2b-d079c30bd823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "IMG_URL = \"https://datasets-server.huggingface.co/assets/derek-thomas/ScienceQA/--/default/train/7/image/image.jpg?Expires=1760691296&Signature=jBrBX5II8NFMSI9RkblePB2GBC-2LDVGvOh7wlChebSDCkz9Zy9SXw-JB3dpjaYc4lSrZJ73VkkqxxRZ52Xjrm4cOs4lGKhg0fu7nFbCl~18Tys56S0yJFPFYW0tBJ0fSZi4VzaGxXgjn5J-CwtPU74amaBGfLw6cT3J~ka-oBrH-DLFhvOkGWbPvkIYofAxmR9NBMDCpnzZUVw1oFAIVmf9OAvetf6EuDYNDh4iz2BJMrsIq2u3r1eln5WZz0cdm8ZC7UABDd5V6PYB1CKMgzfJ7dLiq-LhubrKQl~LFceJP7PgNAMcgw8B7crJqAg3mBvM8bFxIsbVfNSgchaBiQ__&Key-Pair-Id=K3EI6M078Z3AC3\"\n",
    "\n",
    "image = load_image(IMG_URL)\n",
    "\n",
    "# Load model and processor\n",
    "ckpt = \"google/siglip2-base-patch32-256\"\n",
    "model = AutoModel.from_pretrained(ckpt, device_map=\"auto\").eval()\n",
    "processor = AutoProcessor.from_pretrained(ckpt)\n",
    "\n",
    "# Preprocess image\n",
    "inputs = processor(images=image, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    image_embeddings = model.get_image_features(**inputs)\n",
    "\n",
    "print(image_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894b9b8f-0451-40c6-ac3a-97dc3588afcb",
   "metadata": {},
   "source": [
    "### Vision Projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3305329-91a3-42ad-b4bd-965ad8bccb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9e7d40c-5571-4122-9b25-18f90ecd73ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisionProjector(nn.Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int, hidden: int = 1024, n_prefix_tokens: int = 1):\n",
    "        super().__init__()\n",
    "        self.n_prefix = n_prefix_tokens\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden, out_dim * n_prefix_tokens),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        out = out.view(x.size(0), self.n_prefix, -1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c900ebe3-8be0-4abc-a960-a49ff3f8f7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uq bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "09878904-69f0-43cd-96f8-ecc56ac8148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import prepare_model_for_kbit_training, get_peft_model, LoraConfig, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a110a560-d965-4505-8277-a95dcfb367ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_tokenizer_and_model(model_id: str, LOAD_4BIT,B4_COMPUTE_DTYPE):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=False)\n",
    "    if tokenizer.pad_token_id is None:\n",
    "        tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "    # BitsAndBytesConfig\n",
    "    if LOAD_4BIT:\n",
    "        bnb = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=getattr(__import__(\"torch\"), B4_COMPUTE_DTYPE),\n",
    "        )\n",
    "    else:\n",
    "        bnb = None\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        quantization_config=bnb,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "861af81b-19c8-46ee-9e27-30de3774c3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_4BIT = False\n",
    "B4_COMPUTE_DTYPE = \"float16\"\n",
    "tokenizer, model = build_tokenizer_and_model(\"google/gemma-3-1b-it\",LOAD_4BIT,B4_COMPUTE_DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85426959-f0b3-40d4-a6c0-0638dabd1f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "75cb82aa-145b-4a13-b4f6-d630807dc116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a528543f-c4b0-411c-b90c-500a056277e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7679de76-5492-4333-92a8-c18542e3a44d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b5de09-a092-4bff-be41-ac24781c6666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42f6fd3b-21c8-437c-af0a-bd0c03b6bdb5",
   "metadata": {},
   "source": [
    "## Lora setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5bbe399-aa93-4996-aebe-d3c9dce5e8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "LORA_R = 8\n",
    "LORA_ALPHA = 32\n",
    "LORA_TARGET_MODULES = [\n",
    "    \"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"up_proj\", \"down_proj\"\n",
    "]  \n",
    "\n",
    "def apply_peft(model, LORA_R, LORA_ALPHA, LORA_TARGET_MODULES):\n",
    "    lora_conf = LoraConfig(\n",
    "        r=LORA_R,\n",
    "        lora_alpha=LORA_ALPHA,\n",
    "        target_modules=LORA_TARGET_MODULES,\n",
    "        bias=\"none\",\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "    )\n",
    "    model = get_peft_model(model, lora_conf)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9e030701-0c4b-45c0-977d-da0d5e38dc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = apply_peft(model, LORA_R, LORA_ALPHA, LORA_TARGET_MODULES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e9a40bad-d8ce-42dd-968f-e0f9b2221e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86e66b5a-38df-4e18-893c-0ce02b141aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,845,568 || all params: 1,004,731,520 || trainable%: 0.4823\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db3d3c64-141e-4cb6-afba-b42bfb7f1172",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_DIM = image_embeddings.shape[1]\n",
    "T_DIM = model.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1bc50854-8eb7-4b7c-a307-329a7072b156",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX_TOKENS = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9db03851-201d-4aa0-b63e-3939a2808281",
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_proj = VisionProjector(V_DIM, T_DIM, hidden=min(2048, max(512, V_DIM * 2)), n_prefix_tokens=PREFIX_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3a0edcc5-a097-4d9e-bc3b-63e00e27ce3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionProjector(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=1536, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=1536, out_features=1152, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vision_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4ca12c64-0e00-4b14-9a6f-b851f7b2878c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13476/122777054.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  vision_emb = torch.tensor(image_embeddings).unsqueeze(0)\n"
     ]
    }
   ],
   "source": [
    "vision_emb = torch.tensor(image_embeddings).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3d38b5fa-e9b5-459e-8221-58facff931ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the checkpoints\n",
      "Loaded checkpoint\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading the checkpoints\")\n",
    "vision_proj.load_state_dict(torch.load(\"/home/nabin/Desktop/3Drecons/results/phyVQA-train/output_gemma_vision_lora/epoch_2/projector.pt\", map_location=\"cpu\"))\n",
    "model.load_adapter(\"/home/nabin/Desktop/3Drecons/results/phyVQA-train/output_gemma_vision_lora/epoch_2\", \"peft\")\n",
    "print(f\"Loaded checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9eabc3ae-1ba8-427a-b729-b09480d5c378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionProjector(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=1536, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=1536, out_features=1152, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vision_proj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa7a212-86f1-4410-9105-db08ff9716d4",
   "metadata": {},
   "source": [
    "## Finally inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "53b82a05-044e-4b97-9fc6-3c26ef46353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"प्रत्येक नमुनामा रहेका कणहरूको औसत गतिज ऊर्जा तुलना गर्नुहोस्। कुन नमुनाको तापक्रम बढी छ? [\n",
    "\"दुवै होइन; दुवै नमुनाको तापक्रम समान छ\",\n",
    "\"नमूना A\",\n",
    "\"नमूना B\"\n",
    "]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6ac4c2e9-65d0-461d-9efd-0c727aec59e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'प्रत्येक नमुनामा रहेका कणहरूको औसत गतिज ऊर्जा तुलना गर्नुहोस्। कुन नमुनाको तापक्रम बढी छ? [\\n\"दुवै होइन; दुवै नमुनाको तापक्रम समान छ\",\\n\"नमूना A\",\\n\"नमूना B\"\\n]'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e016846f-5a32-41c1-a417-98f795ffad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "be100ff2-51ae-4393-b06f-28f37f5843be",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_embeds = model.get_input_embeddings()(inputs.input_ids)\n",
    "proj = vision_proj(vision_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7e33a552-804c-4d81-b347-56df3aefcf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_embeds = torch.cat([proj, inputs_embeds], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cddc0289-7c38-42bf-8148-5548c48bac13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0811,  0.1031,  0.1283,  ...,  0.1366,  0.0183, -0.0527],\n",
       "         [ 0.1388, -0.2165, -0.5386,  ..., -0.2465,  0.0267,  0.1258],\n",
       "         [-0.1833, -0.6753,  1.4335,  ..., -0.5510, -0.8576, -0.6173],\n",
       "         ...,\n",
       "         [ 0.6091,  0.2434,  1.3673,  ...,  1.8644,  1.2844,  0.5013],\n",
       "         [ 0.9778, -0.5925, -0.5759,  ..., -0.1844, -0.5013,  0.3687],\n",
       "         [ 0.1020,  1.5910,  0.4495,  ...,  0.3853,  0.0593,  2.1130]]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "afae6ea8-e9d6-4e50-a9fb-548b8da06424",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_mask = torch.ones((1, proj.size(1)), dtype=inputs.attention_mask.dtype)\n",
    "attn_mask = torch.cat([prefix_mask, inputs.attention_mask], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4cc5195e-9335-4570-ae95-8a4989e691cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: प्रत्येक नमुनामा रहेका कणहरूको औसत गतिज ऊर्जा तुलना गर्नुहोस्। कुन नमुनाको तापक्रम बढी छ? [\n",
      "\"दुवै होइन; दुवै नमुनाको तापक्रम समान छ\",\n",
      "\"नमूना A\",\n",
      "\"नमूना B\"\n",
      "]\n",
      "Generated text: \n",
      "सही उत्तर हुन्:\n",
      "A. नमूना A\n",
      "B. नमूना B\n",
      "C. नमूना C\n",
      "D. न कुनै पनि\n",
      "सही उत्तर हुन्:\n",
      "A. नमूना A\n",
      "B. नमूना B\n",
      "C. नमूना C\n",
      "D. न कुनै पनि\n",
      "\n",
      "उत्तर: A\n"
     ]
    }
   ],
   "source": [
    "print(f\"Prompt: {prompt}\")\n",
    "outputs = model.generate(\n",
    "        inputs_embeds=inputs_embeds,\n",
    "        attention_mask=attn_mask,\n",
    "        max_new_tokens=64,\n",
    "        do_sample=False,\n",
    "    )\n",
    "\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"Generated text:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309d2272-9aca-4c2a-baec-cfb71fe4dd34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286ef2c8-f651-480e-ab0a-dc58b30aa0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
